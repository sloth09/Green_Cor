# GEMINI Project Analysis: Green Corridor Optimization Model

## 1. Project Overview

This project is a sophisticated techno-economic analysis and optimization tool designed for planning **ammonia bunkering infrastructure** for a maritime "Green Corridor". It utilizes a Mixed-Integer Linear Programming (MILP) model to determine the most cost-effective fleet of shuttle tankers and pump systems to meet a growing demand for ammonia fuel over a 20-year horizon (2030-2050).

The core purpose is to minimize the Net Present Cost (NPC) of the entire bunkering supply chain by evaluating hundreds of scenarios. These scenarios model different operational strategies, such as using a large, port-side storage tank versus direct long-distance transport from production facilities (e.g., Yeosu, Ulsan).

### Key Technologies:
- **Core Logic (Python):**
    - **`pulp`:** For building and solving the MILP optimization model.
    - **`pandas` & `numpy`:** For data manipulation, analysis, and numerical calculations.
    - **`pyyaml`:** For managing a highly flexible, configuration-driven workflow.
    - **`python-docx` & `openpyxl`:** For exporting results into structured reports.
- **Reporting (Node.js):**
    - **`docx`:** For programmatically generating polished Word document reports that include text, tables, and figures generated by the Python analysis.

### Architecture:
- **Configuration-Driven:** The entire system is controlled via `.yaml` files in the `config/` directory. This allows for easy modification of economic parameters, technical specifications, and execution modes without changing the source code.
- **Modular Python (`src/`):** The Python codebase is well-structured into modules responsible for specific tasks like cost calculation (`cost_calculator.py`), operational timing (`cycle_time_calculator.py`), and optimization (`optimizer.py`).
- **Data-Centric Workflow:** The Python model produces detailed CSV and Excel files in the `results/` directory. These files are then used by `analysis_and_visualization.py` to create plots, which are subsequently embedded into the final DOCX report by the `generate_report.js` script.
- **Documentation:** The project includes extensive documentation in the `docs/` directory, explaining the model's methodology, assumptions, and key findings.

## 2. Building and Running

### Step 1: Install Dependencies

You need to set up both Python and Node.js environments.

- **Python Setup:**
  ```bash
  # Create and activate a virtual environment
  python -m venv .venv
  # On Windows
  # .\.venv\Scripts\activate
  # On macOS/Linux
  source .venv/bin/activate

  # Install required packages
  pip install -r requirements.txt
  ```

- **Node.js Setup:**
  ```bash
  # Install required packages
  npm install
  ```

### Step 2: Running the Analysis (Python)

The execution is controlled by editing the `execution` section in `config/base.yaml`.

- **To run a full optimization for a single case:**
  1.  In `config/base.yaml`, set `run_mode: "single"` and `single_case: "case_1"`.
  2.  Execute `python main.py`.
  3.  Results will be saved in the `results/` directory.

- **To run a quick, single-scenario time calculation (no optimization):**
  1.  In `config/base.yaml`, set `run_mode: "single_scenario"`.
  2.  Specify `single_case`, `single_scenario_shuttle_cbm`, and `single_scenario_pump_m3ph`.
  3.  Execute `python main.py`.

- **To run multiple cases in parallel:**
  1.  In `config/base.yaml`, set `run_mode: "multiple"` or `"all"`.
  2.  If using `"multiple"`, define the cases in the `multi_cases` list.
  3.  Set the number of parallel workers with `num_jobs`.
  4.  Execute `python run_all_cases.py` for faster, parallel processing.

### Step 3: Generating Reports

- **Generate Plots:**
  - Run the `analysis_and_visualization.py` script to generate figures from the CSV results.
  - `python analysis_and_visualization.py`

- **Generate Final Word Document:**
  1.  Ensure the analysis has been run and figures exist in `results/figures/`.
  2.  Execute `node generate_report.js`.
  3.  The final report, `Green_Corridor_Report.docx`, will be created in the `results/` directory.

## 3. Development Conventions

- **Configuration as Code:** All model parameters and execution settings are defined in YAML files. This is the primary method for controlling the application. Do not hardcode parameters in scripts.
- **Modularity:** The Python logic is highly modular. When adding new calculations or features, create or extend the appropriate module in the `src/` directory (e.g., add new cost logic to `cost_calculator.py`).
- **Testing:** The presence of a `tests/` directory indicates that automated tests are used. Any new feature or bug fix should be accompanied by corresponding tests.
- **Data Flow:** The standard workflow is `Python analysis -> CSV/Excel results -> Plot generation -> DOCX report`. Follow this pattern when extending reporting capabilities.
- **Code Style:** The code is well-commented and uses type hints. Adhere to this style for new contributions.
- **Documentation:** For significant changes to methodology or assumptions, update the relevant Markdown files in the `docs/` directory.

## 4. Architectural Insights and Development History

This section summarizes key information from `CLAUDE.md`, which provides a detailed log of the project's evolution.

### Architectural Evolution
The project has undergone significant refactoring from its initial version (`MILPmodel_v17_250811.py`), which was a single, monolithic script. The current architecture emphasizes modularity and clear separation of concerns.

- **From Monolith to Modules:** The logic was broken down from a single script into a structured `src/` package.
- **Centralized Calculators:** Core business logic has been extracted into dedicated, reusable library modules:
    - `src/cycle_time_calculator.py`: Provides a single source of truth for all operational time calculations (e.g., shuttle travel, pumping, port operations) for all cases.
    - `src/fleet_sizing_calculator.py`: Unifies the logic for calculating the required number of shuttles, ensuring consistency between different run modes.
    - `src/cost_calculator.py`: Centralizes all CAPEX and OPEX calculations.

### Core Calculation Logic: Time Structure
A critical aspect of the model is the detailed calculation of the "total cycle time" for a bunkering operation, which differs significantly between scenarios.

- **Case 1 (Busan Port Storage):** A shuttle operates in multiple short trips within the port.
    - **Cycle Time Components:** Shore Loading (from port tank to shuttle) + Outbound Travel (within port) + Bunkering Operation (to vessel) + Return Travel.
    - The pumping time is determined by the shuttle's own size (`shuttle_size / pump_rate`).

- **Case 2 (Long-distance Transport):** A large shuttle travels from a production facility (Ulsan/Yeosu) and services multiple vessels in a single trip.
    - **Cycle Time Components:** Shore Loading + Long-distance Travel (to Busan) + Port Entry + Multiple Bunkering Operations (one for each vessel served) + Port Exit + Long-distance Return Travel.
    - The pumping time for each operation is determined by the target vessel's fuel need (`bunker_volume_per_call_m3 / pump_rate`).
    - The number of vessels served per trip is calculated as `floor(shuttle_size / bunker_volume_per_call)`.

### Significant Version Updates & Bug Fixes
The `CLAUDE.md` file tracks important changes that provide context for the current state of the code:
- **v2.1:** Corrected a major bug where Case 2 (long-distance) was only calculating one-way travel time and fuel costs, underestimating the total cost.
- **v2.3:** A significant architectural update that unified the calculation logic for Case 1 and Case 2 by introducing the `cycle_time_calculator.py` and separating their distinct operational steps.
- **v2.3.1:** Fixed a critical bug where pump fuel costs were being incorrectly calculated as double the actual cost. This unified the cost logic between the `annual_simulation` mode and the full `optimizer`.
- **v2.3.2:** Further unified the codebase by introducing `fleet_sizing_calculator.py` to ensure consistent fleet size calculations across the entire application. It also standardized the definition of "annual calls" (`y[t]`) in the MILP model for all cases.
